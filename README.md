# Cloud-computing: Tìm hiểu Parquet  và viết ứng dụng Demo
## Công nghệ sử dụng:
Dịch vụ:
- Amazon S3
- AWS EMR

Framework:
- Apache Hadoop
- Spark
## Thông Tin Thành Viên Nhóm:
- Trần Văn Kiệt - 20110665
- Nguyễn Đình Thiện - 2011263
- Nguyễn Công Thành - 20110267 

Contributors:
[![](https://avatars.githubusercontent.com/u/89686453?s=64&v=4)](https://www.facebook.com/kTw1208)
[![](https://avatars.githubusercontent.com/u/116097599?s=64&v=4s)](https://www.facebook.com/thien20110263)
[![](https://avatars.githubusercontent.com/u/89307218?v=4&s=64)](https://www.facebook.com/profile.php?id=100011055702857)
## Yêu cầu:
- Thư viện: https://spark.apache.org/
- Đọc ghi file trong Hadoop, sử dụng mô hình MapReduce
- Yêu cầu chi tiết:
   + Cài đặt Hadoop gồm 1 namenode và 2 slavesnode
   + Chuyển file CSV sang Parquet
   + Đọc, ghi file Parquet trong Hadoop sử dụng mô hình MapReduce
   + File CSV download từ challange: https://www.kaggle.com/c/riiid-test-answer-prediction
## Nội dung:
Sử dụng hadoop mapreduce và spark để đọc ghi file trên cluster
## Mục tiêu:
So sánh lợi ích của việc đọc, ghi file Parquet trong Hadoop sử dụng mô hình MapReduce với cách đọc thông thường.
## Tài liệu tham khảo:

